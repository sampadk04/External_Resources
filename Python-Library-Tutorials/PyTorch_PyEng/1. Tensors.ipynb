{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing other dependencies\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# importing PyTorch\n",
    "import torch\n",
    "\n",
    "# checks whether MPS is available\n",
    "print(torch.backends.mps.is_available())\n",
    "\n",
    "# this ensures that the current current PyTorch installation was built with MPS activated.\n",
    "print(torch.backends.mps.is_built())\n",
    "\n",
    "# setting the device to \"mps\" instead of default \"cpu\"\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Playing around with Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Creating Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# creates a custom tensor from the given list of imputs (like numpy)\n",
    "x = torch.IntTensor([1, 2, 3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n"
     ]
    }
   ],
   "source": [
    "# creates a custom tensor from the given list of imputs (like numpy)\n",
    "x = torch.FloatTensor([1., 2., 3.])\n",
    "print(x)\n",
    "# by default, Tensors have the datatype 'Float' imbedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# creates an empty tensor of size 3\n",
    "x = torch.empty(3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00, -1.5846e+29]])\n"
     ]
    }
   ],
   "source": [
    "# a 2D tensor of size (2,3)\n",
    "x = torch.empty(2,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2355, 0.5542, 0.1524],\n",
      "        [0.8502, 0.3206, 0.9898]])\n"
     ]
    }
   ],
   "source": [
    "# tensor of size (2,3) with random initialization\n",
    "x = torch.rand(2,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# tensor of size (2,3) with 'zero' initialization\n",
    "x = torch.zeros(2,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# tensor of size (2,3) with 'ones' initialization\n",
    "x = torch.ones(2,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Managing the Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1],\n",
      "        [1, 1]])\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "# creates a tensor of size (2,2) consisting of ones, with datatype 'int64'\n",
    "x = torch.ones(2,2, dtype=torch.int64)\n",
    "print(x)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], dtype=torch.float64)\n",
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "# creates a tensor of size (2,2) consisting of ones, with datatype 'float64'\n",
    "x = torch.ones(2,2, dtype=torch.float64)\n",
    "print(x)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Mangaging Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2],\n",
    "                [3, 4]])\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2\n"
     ]
    }
   ],
   "source": [
    "n,m = x.size()\n",
    "print(n,m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3378, 0.5954],\n",
      "        [0.7578, 0.2830]])\n",
      "tensor([[0.8573, 0.5410],\n",
      "        [0.8054, 0.5486]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2, 2)\n",
    "print(x)\n",
    "y = torch.rand(2, 2)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1950, 1.1364],\n",
      "        [1.5633, 0.8317]])\n",
      "tensor([[-0.5195,  0.0544],\n",
      "        [-0.0476, -0.2656]])\n",
      "tensor([[0.2896, 0.3221],\n",
      "        [0.6104, 0.1553]])\n",
      "tensor([[0.3940, 1.1005],\n",
      "        [0.9409, 0.5159]])\n"
     ]
    }
   ],
   "source": [
    "# element-wise operations on x and y\n",
    "\n",
    "# addition\n",
    "z = x + y\n",
    "# torch.add(x,y)\n",
    "print(z)\n",
    "\n",
    "# subtraction\n",
    "z = x - y\n",
    "# z = torch.sub(x, y)\n",
    "print(z)\n",
    "\n",
    "# multiplication\n",
    "z = x * y\n",
    "# z = torch.mul(x,y)\n",
    "print(z)\n",
    "\n",
    "# division\n",
    "z = x / y\n",
    "# z = torch.div(x,y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do the operations in-place.\n",
    "\n",
    "In PyTorch, every in-place operation has a underscore `funcName_` attached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8573, 0.5410],\n",
      "        [0.8054, 0.5486]])\n",
      "tensor([[1.1950, 1.1364],\n",
      "        [1.5633, 0.8317]])\n"
     ]
    }
   ],
   "source": [
    "# Initial 'y'\n",
    "print(y)\n",
    "# 'y' after addition, replaced in-place\n",
    "y.add_(x)\n",
    "# Final 'y'\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Slicing Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5706, 0.8786, 0.1238],\n",
      "        [0.5661, 0.2394, 0.0284],\n",
      "        [0.1308, 0.6287, 0.5310],\n",
      "        [0.5859, 0.9591, 0.8003],\n",
      "        [0.5313, 0.0258, 0.6176]])\n",
      "tensor([0.5706, 0.5661, 0.1308, 0.5859, 0.5313])\n",
      "tensor([0.5661, 0.2394, 0.0284])\n",
      "tensor(0.2394)\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5,3)\n",
    "print(x)\n",
    "print(x[:, 0]) # all rows, column 0\n",
    "print(x[1, :]) # row 1, all columns\n",
    "print(x[1,1]) # element at 1, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2394324541091919\n"
     ]
    }
   ],
   "source": [
    "# Get the actual value if only 1 element in your tensor\n",
    "print(x[1,1].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Reshaping Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "# Reshape with torch.view()\n",
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8)\n",
    "# the size -1 is inferred from other dimensions\n",
    "# if -1, pytorch will automatically determine the necessary size\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Converting Tensors to Numpy and vice-versa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Converting Tensors to Numpy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "x_tensor = torch.ones(2,2)\n",
    "print(x_tensor)\n",
    "print(type(x_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1.]\n",
      " [1. 1.]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "x_numpy = x_tensor.numpy()\n",
    "print(x_numpy)\n",
    "print(type(x_numpy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Converting Numpy Arrays to Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "x_tensor_new = torch.tensor(x_numpy)\n",
    "print(x_tensor_new)\n",
    "print(type(x_tensor_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Caution:** While using GPU device for variables, it will give an error, if we want to convert the arrays to numpy and vice-versa. So, for this we have to make sure to use CPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Attaching `grad`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `requires_grad` argument in the Tensors will tell PyTorch that it will need to calculate the gradients for this tensor, later in the optimization steps, i.e. this if this is a variable in the model that we want to optimize, we can extract it's gradient at any point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([5.5, 3], requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Using GPU to store variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default all tensors are created on the CPU, but we can also move them to the GPU (only if it's available)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# since, we have apple metal GPU available, we have already set the device to 'MPS' in the imports cell above\n",
    "device\n",
    "# this is an MPS device object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# directly create a tensor on GPU\n",
    "x = torch.ones((2,2), device=device)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones((2,2))\n",
    "print(x)\n",
    "# indirectly convert to a tensor on GPU\n",
    "y = x.to(device)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, mps:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/sampadk04/Desktop/Programming/VSCode-Projects/Python/PyTorch_PyEng/notebooks/Tensors.ipynb Cell 44'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sampadk04/Desktop/Programming/VSCode-Projects/Python/PyTorch_PyEng/notebooks/Tensors.ipynb#ch0000048?line=0'>1</a>\u001b[0m \u001b[39m# we can't operate on variables present on two different devices\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sampadk04/Desktop/Programming/VSCode-Projects/Python/PyTorch_PyEng/notebooks/Tensors.ipynb#ch0000048?line=1'>2</a>\u001b[0m z \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39;49m y\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, mps:0 and cpu!"
     ]
    }
   ],
   "source": [
    "# we can't operate on variables present on two different devices\n",
    "z = x + y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('conda_pytorch_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5e3ed40c8fb4c0778cc14e83fd08fd290bb35159f9df4bcbc4cc74f240b0dd9d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
